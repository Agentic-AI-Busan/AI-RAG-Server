services:
  ai-server:
    init: true
    container_name: ai-server
    environment:
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      LANGCHAIN_TRACING_V2: ${LANGCHAIN_TRACING_V2}
      LANGCHAIN_ENDPOINT: ${LANGCHAIN_ENDPOINT}
      LANGCHAIN_API_KEY: ${LANGCHAIN_API_KEY}
      LANGCHAIN_PROJECT: ${LANGCHAIN_PROJECT}
    build:
      context: ./ai-server
      dockerfile: Dockerfile  # 아래에 Dockerfile 예시 참고
    volumes:
      - ./ai-server/project:/project
    ports:
      - "80:8000"  # 호스트의 8000 포트를 컨테이너의 8000 포트
    networks:
      - app_network

  ai-preprocessing:
    init: true
    container_name: ai-preprocessing
    environment:
      OPENAI_API_KEY: ${OPENAI_API_KEY}
    build:
      context: ./ai-preprocessing
      dockerfile: Dockerfile  # 아래에 Dockerfile 예시 참고
    volumes:
      - ./ai-preprocessing/project:/project
      - ./data:/project/data
    networks:
      - app_network

  streamlit-app:
    init: true
    container_name: streamlit-app
    build:
      context: ./streamlit-app
      dockerfile: Dockerfile
    ports:
      - "443:8501"
    volumes:
      - ./streamlit-app:/app
    environment:
      - API_BASE_URL=http://ai-server:8000
      - PYTHONUNBUFFERED=1
    depends_on:
      - ai-server
    networks:
      - app_network

networks:
  app_network:
    driver: bridge